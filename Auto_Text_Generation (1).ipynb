{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Auto Text Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42ad59edfb2b41949f0818d70091058a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_91ea384e1e2c41bfa46a49e4a22ac7c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23733eb45c934caeb080288c6e7f7a59",
              "IPY_MODEL_ed7a2ddbc1aa4b719718152fcced88cd"
            ]
          }
        },
        "91ea384e1e2c41bfa46a49e4a22ac7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23733eb45c934caeb080288c6e7f7a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14418ac281df477c8933980309d55289",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 64776,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 64776,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5950f9cf90b64419895d2f67be8838c2"
          }
        },
        "ed7a2ddbc1aa4b719718152fcced88cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3938ae171e694a0e9dc0410792128591",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 64776/64776 [03:26&lt;00:00, 313.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67663d1f08bd43239fea0aa7b44c8134"
          }
        },
        "14418ac281df477c8933980309d55289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5950f9cf90b64419895d2f67be8838c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3938ae171e694a0e9dc0410792128591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67663d1f08bd43239fea0aa7b44c8134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuf8nrwTdj_V"
      },
      "source": [
        "### **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv1Zk2Dkdvv3"
      },
      "source": [
        "import pickle\r\n",
        "import re\r\n",
        "import spacy\r\n",
        "import nltk\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-A8cJRndyP8"
      },
      "source": [
        "### **Mounting Google derive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVj7k31EdpoI",
        "outputId": "ee10670b-1733-415e-cf4a-7647017886b9"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hks9uyo7NfQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa055b08-6c59-4b44-dadc-f834307261d9"
      },
      "source": [
        "seed = 2019\r\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7d698ce048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlxPCQjneI-E"
      },
      "source": [
        "### **Loading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cT46nZVYKBp",
        "outputId": "a284b93a-d741-4731-f849-243b5a1631df"
      },
      "source": [
        "with open('/content/drive/MyDrive/Dailog-dataset.dialogs_dataset','rb') as f:\r\n",
        " df = pickle.load(f)\r\n",
        "df[:10]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Hi, I'm looking to book a table for Korean fod\",\n",
              " 'Somewhere in Southern NYC, maybe the East Village?',\n",
              " \" We don't want to sit at the bar, but anywhere else is fine\",\n",
              " 'What times are available?',\n",
              " \"Yikes, we can't do those times\",\n",
              " 'Let me check',\n",
              " \"Great, let's book that\",\n",
              " \"No, that's it, just book\",\n",
              " 'Hi I would like to see if the Movie What Men Want is playing here',\n",
              " 'Yes, for me and a friend so two tickets please']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1ky64DJeWEK"
      },
      "source": [
        "### **Preparing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHnH3cTuYV8O",
        "outputId": "b5166e19-5ae3-4e55-c41f-17ce583a5432"
      },
      "source": [
        "type(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGVYK0ryZTzc"
      },
      "source": [
        "clean_df = []\r\n",
        "for i in df:\r\n",
        "  i = re.sub(\"[^a-zA-Z']\",\" \",i)\r\n",
        "  i = i.lower()\r\n",
        "  clean_df.append(i)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpCvbPBd0tSQ",
        "outputId": "270b99b3-0021-4687-c6ca-3fef1eb1e143"
      },
      "source": [
        "clean_df[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"hi  i'm looking to book a table for korean fod\",\n",
              " 'somewhere in southern nyc  maybe the east village ',\n",
              " \" we don't want to sit at the bar  but anywhere else is fine\",\n",
              " 'what times are available ',\n",
              " \"yikes  we can't do those times\",\n",
              " 'let me check',\n",
              " \"great  let's book that\",\n",
              " \"no  that's it  just book\",\n",
              " 'hi i would like to see if the movie what men want is playing here',\n",
              " 'yes  for me and a friend so two tickets please']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ved7KxZ16mZf"
      },
      "source": [
        "all_text = \" \".join(clean_df)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9OuBCOn-pIT"
      },
      "source": [
        "token = all_text.split()\r\n",
        "BOW = {}\r\n",
        "for word in token:\r\n",
        "  if word not in BOW.keys():\r\n",
        "    BOW[word] = 1\r\n",
        "  else:\r\n",
        "    BOW[word] +=1\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyoFExI4-1Lp"
      },
      "source": [
        "word_count = pd.DataFrame({'word':BOW.keys(),'count':BOW.values()})\r\n",
        "word_count = word_count.sort_values(by = ['count'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "g170ttKK_oi8",
        "outputId": "9477f3c2-bdfa-4933-f447-bb2b6ac8ab15"
      },
      "source": [
        "word_count.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10949</th>\n",
              "      <td>tabs</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7881</th>\n",
              "      <td>genres</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4217</th>\n",
              "      <td>gakus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7882</th>\n",
              "      <td>indecisive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7883</th>\n",
              "      <td>emagine</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             word  count\n",
              "10949        tabs      1\n",
              "7881       genres      1\n",
              "4217        gakus      1\n",
              "7882   indecisive      1\n",
              "7883      emagine      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "5v9nyghGAeK2",
        "outputId": "d24dc50f-709d-4c57-effc-04415adbd731"
      },
      "source": [
        "word_count.tail()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>you</td>\n",
              "      <td>11928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a</td>\n",
              "      <td>13390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>14003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>the</td>\n",
              "      <td>15410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>i</td>\n",
              "      <td>19881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word  count\n",
              "69  you  11928\n",
              "5     a  13390\n",
              "3    to  14003\n",
              "15  the  15410\n",
              "47    i  19881"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGh7s39GA9S2"
      },
      "source": [
        "rare_threshold = 3\r\n",
        "\r\n",
        "rare_words = len(word_count[word_count['count'] < rare_threshold]) ## Selecting all the words that appear less than 3 times in whole text as rare words\r\n",
        "total_words = len(word_count)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeiJRVsbB6VC"
      },
      "source": [
        "rare_words_dist = rare_words/total_words*100\r\n",
        "rare_words_corpus = word_count[word_count['count'] < rare_threshold]['count'].sum()/word_count['count'].sum()*100"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCIxkEAeDAOh",
        "outputId": "cbf36eae-bf66-4636-a6a6-74f6f64344ad"
      },
      "source": [
        "print('The rare words percentage distribution :',rare_words_dist)\r\n",
        "print('The rare words percentage distribution in corpus:',rare_words_corpus)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The rare words percentage distribution : 61.61643835616438\n",
            "The rare words percentage distribution in corpus: 1.742686062912748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYm2yWp5Dimy",
        "outputId": "186c9d14-3fac-404c-e124-031fdaac6aa5"
      },
      "source": [
        "rare_words = word_count[word_count['count'] < rare_threshold]['word'].tolist()\r\n",
        "rare_words[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tabs',\n",
              " 'genres',\n",
              " 'gakus',\n",
              " 'indecisive',\n",
              " 'emagine',\n",
              " 'brissago',\n",
              " \"monster's\",\n",
              " 'idk',\n",
              " 'thingy',\n",
              " 'lucas']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "42ad59edfb2b41949f0818d70091058a",
            "91ea384e1e2c41bfa46a49e4a22ac7c4",
            "23733eb45c934caeb080288c6e7f7a59",
            "ed7a2ddbc1aa4b719718152fcced88cd",
            "14418ac281df477c8933980309d55289",
            "5950f9cf90b64419895d2f67be8838c2",
            "3938ae171e694a0e9dc0410792128591",
            "67663d1f08bd43239fea0aa7b44c8134"
          ]
        },
        "id": "cbWMI2bIFb84",
        "outputId": "516e8f9a-1bb5-44bc-b0e1-9d5475a8713c"
      },
      "source": [
        "data = []                                 \r\n",
        "for sents in tqdm_notebook(clean_df):\r\n",
        "  for word in sents:                           # Removing the rare words with unknown token in text\r\n",
        "    if word in rare_words:\r\n",
        "      sent = re.sub(word,'<unk>',sents)\r\n",
        "      data.append(sent)\r\n",
        "\r\n",
        "  \r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42ad59edfb2b41949f0818d70091058a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=64776.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7u1TYOEMDyx",
        "outputId": "58e2f0f6-3761-47bb-c2ba-f82ad17c689a"
      },
      "source": [
        "data[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi  i<unk>m looking to book a table for korean fod',\n",
              " ' we don<unk>t want to sit at the bar  but anywhere else is fine',\n",
              " 'yikes  we can<unk>t do those times',\n",
              " 'great  let<unk>s book that',\n",
              " 'no  that<unk>s it  just book',\n",
              " 'let<unk>s watch another movie then',\n",
              " 'let<unk>s watch how to train your dragon',\n",
              " 'i want to order a pi<unk><unk>a from bertuccis in chelmsford  ma',\n",
              " 'i want to order a pi<unk><unk>a from bertuccis in chelmsford  ma',\n",
              " ' i would like a sporkie pi<unk><unk>a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-VgtYSANFRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23db577-1d3b-4940-da70-520dd110072d"
      },
      "source": [
        "len(token)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "477137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AZpbQ39dQF1"
      },
      "source": [
        "# capture length of all the sequences\r\n",
        "\r\n",
        "text_word_count = []\r\n",
        "for i in data:\r\n",
        "  text_word_count.append(len(i.split()))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "fcjfuRbQfJLM",
        "outputId": "b6988018-4a3c-418d-a7a6-3adc92f10b17"
      },
      "source": [
        "pd.Series(text_word_count).hist(bins = 30,range = (0,30))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d191ddc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWEJ3UAWfWcZ"
      },
      "source": [
        "def create_seq(text,seq_len = 8):           # Choose sequence length 8 as most of the sentence in text are of less than 10 \r\n",
        "\r\n",
        "  sequences = []\r\n",
        "\r\n",
        "  if len(text.split()) > seq_len:\r\n",
        "    for i in range(seq_len,len(text.split())):\r\n",
        "      seq = text.split()[i-seq_len:i+1]\r\n",
        "      sequences.append(\" \".join(seq))\r\n",
        "    return sequences\r\n",
        "\r\n",
        "  else:\r\n",
        "    return [text]\r\n",
        "\r\n",
        " "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUBR0FGd4y0O"
      },
      "source": [
        "seqs = [create_seq(i) for i in data]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRARby0i5-A3",
        "outputId": "651f5666-6438-48af-f3f5-d116047b4029"
      },
      "source": [
        "seqs[:15]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hi i<unk>m looking to book a table for korean',\n",
              "  'i<unk>m looking to book a table for korean fod'],\n",
              " ['we don<unk>t want to sit at the bar but',\n",
              "  'don<unk>t want to sit at the bar but anywhere',\n",
              "  'want to sit at the bar but anywhere else',\n",
              "  'to sit at the bar but anywhere else is',\n",
              "  'sit at the bar but anywhere else is fine'],\n",
              " ['yikes  we can<unk>t do those times'],\n",
              " ['great  let<unk>s book that'],\n",
              " ['no  that<unk>s it  just book'],\n",
              " ['let<unk>s watch another movie then'],\n",
              " ['let<unk>s watch how to train your dragon'],\n",
              " ['i want to order a pi<unk><unk>a from bertuccis in',\n",
              "  'want to order a pi<unk><unk>a from bertuccis in chelmsford',\n",
              "  'to order a pi<unk><unk>a from bertuccis in chelmsford ma'],\n",
              " ['i want to order a pi<unk><unk>a from bertuccis in',\n",
              "  'want to order a pi<unk><unk>a from bertuccis in chelmsford',\n",
              "  'to order a pi<unk><unk>a from bertuccis in chelmsford ma'],\n",
              " [' i would like a sporkie pi<unk><unk>a'],\n",
              " [' i would like a sporkie pi<unk><unk>a'],\n",
              " ['hi i<unk>d like to order two large pizzas'],\n",
              " [\"hi i'd like to order two large pi<unk><unk>as\"],\n",
              " [\"hi i'd like to order two large pi<unk><unk>as\"],\n",
              " ['i<unk>ll have a hawaiian please']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gWW-oaP7KH0"
      },
      "source": [
        "seqs = sum(seqs,[])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPOHCs997YNK",
        "outputId": "0fec3c5d-bc77-4ab9-9f2f-9c4df1f305b2"
      },
      "source": [
        "seqs[:15]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi i<unk>m looking to book a table for korean',\n",
              " 'i<unk>m looking to book a table for korean fod',\n",
              " 'we don<unk>t want to sit at the bar but',\n",
              " 'don<unk>t want to sit at the bar but anywhere',\n",
              " 'want to sit at the bar but anywhere else',\n",
              " 'to sit at the bar but anywhere else is',\n",
              " 'sit at the bar but anywhere else is fine',\n",
              " 'yikes  we can<unk>t do those times',\n",
              " 'great  let<unk>s book that',\n",
              " 'no  that<unk>s it  just book',\n",
              " 'let<unk>s watch another movie then',\n",
              " 'let<unk>s watch how to train your dragon',\n",
              " 'i want to order a pi<unk><unk>a from bertuccis in',\n",
              " 'want to order a pi<unk><unk>a from bertuccis in chelmsford',\n",
              " 'to order a pi<unk><unk>a from bertuccis in chelmsford ma']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOfLpb-m7cTP",
        "outputId": "737301c8-0fc9-41f8-b3ae-f39e6c214d2e"
      },
      "source": [
        "len(seqs)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67993"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQecNK_X7j2s"
      },
      "source": [
        "x = []\r\n",
        "y = []\r\n",
        "\r\n",
        "for i in seqs:\r\n",
        "  x.append(\" \".join(i.split()[:-1]))\r\n",
        "  y.append(\" \".join(i.split()[1:]))\r\n",
        "\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjbOmLnk8iB6",
        "outputId": "8f8e0d4b-e3ad-4e7e-b68d-176ea87bc134"
      },
      "source": [
        "x[0]  , y[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hi i<unk>m looking to book a table for',\n",
              " 'i<unk>m looking to book a table for korean')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LGvcWhD8mgr"
      },
      "source": [
        "int2token = {}                              # Giving each token or word in text a unique interger name which help in converting text into integer\r\n",
        "cnt = 1\r\n",
        "\r\n",
        "for w in set(\" \".join(data).split()):\r\n",
        "  int2token[cnt] = w\r\n",
        "  cnt +=1\r\n",
        "\r\n",
        "token2int = {t:i for i,t in int2token.items()}\r\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hc-4Iqro_t2t",
        "outputId": "4dbcc477-e7f8-44e9-bcfc-5d7301682d6f"
      },
      "source": [
        "token2int['can']"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ovl_t8I4_55l",
        "outputId": "65a0559e-1fa1-477e-c605-3f6c739eaebf"
      },
      "source": [
        "int2token[5181]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'monster'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I9AshjO_9aC"
      },
      "source": [
        "x_tr = x[:50000]\r\n",
        "y_tr = y[:50000]\r\n",
        "\r\n",
        "x_val = x[50000:]\r\n",
        "y_val = y[50000:]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "WpccdwigARiT",
        "outputId": "1e5bb9f6-9426-4033-88a5-d23099072151"
      },
      "source": [
        "# plot sequence length in train set\r\n",
        "text_word_count = []\r\n",
        "\r\n",
        "for i in x_tr:\r\n",
        "  text_word_count.append(len(i.split()))\r\n",
        "\r\n",
        "pd.Series(text_word_count).hist(bins = 70,range=(0,30))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d17a8a2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBae106yEl2I"
      },
      "source": [
        "max_text_len = 8                           # Padding the sequence to make it of equal length\r\n",
        "\r\n",
        "def pad_sequence(seq,n):\r\n",
        "  seq = seq.split()\r\n",
        "\r\n",
        "  if len(seq) < 8:\r\n",
        "    for i in range(n-len(seq)):\r\n",
        "      seq.append('<pad>')\r\n",
        "\r\n",
        "  return \" \".join(seq)\r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRwCCS2gcCdO"
      },
      "source": [
        "x_tr_padded = [pad_sequence(s,max_text_len) for s in x_tr]\r\n",
        "y_tr_padded = [pad_sequence(s,max_text_len) for s in y_tr]\r\n",
        "\r\n",
        "x_val_padded = [pad_sequence(s,max_text_len) for s in x_val]\r\n",
        "y_val_padded = [pad_sequence(s,max_text_len) for s in y_val]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl_rwB3Qddrm",
        "outputId": "6dbd9ffe-8ef1-49b2-bb9a-973a85c77788"
      },
      "source": [
        "x_tr_padded[:20]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi i<unk>m looking to book a table for',\n",
              " 'i<unk>m looking to book a table for korean',\n",
              " 'we don<unk>t want to sit at the bar',\n",
              " 'don<unk>t want to sit at the bar but',\n",
              " 'want to sit at the bar but anywhere',\n",
              " 'to sit at the bar but anywhere else',\n",
              " 'sit at the bar but anywhere else is',\n",
              " 'yikes we can<unk>t do those <pad> <pad> <pad>',\n",
              " 'great let<unk>s book <pad> <pad> <pad> <pad> <pad>',\n",
              " 'no that<unk>s it just <pad> <pad> <pad> <pad>',\n",
              " 'let<unk>s watch another movie <pad> <pad> <pad> <pad>',\n",
              " 'let<unk>s watch how to train your <pad> <pad>',\n",
              " 'i want to order a pi<unk><unk>a from bertuccis',\n",
              " 'want to order a pi<unk><unk>a from bertuccis in',\n",
              " 'to order a pi<unk><unk>a from bertuccis in chelmsford',\n",
              " 'i want to order a pi<unk><unk>a from bertuccis',\n",
              " 'want to order a pi<unk><unk>a from bertuccis in',\n",
              " 'to order a pi<unk><unk>a from bertuccis in chelmsford',\n",
              " 'i would like a sporkie <pad> <pad> <pad>',\n",
              " 'i would like a sporkie <pad> <pad> <pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzT4Kxrld81f",
        "outputId": "eca49e57-6c0a-4607-a144-01ba6949f2c1"
      },
      "source": [
        "y_tr_padded[:20]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i<unk>m looking to book a table for korean',\n",
              " 'looking to book a table for korean fod',\n",
              " 'don<unk>t want to sit at the bar but',\n",
              " 'want to sit at the bar but anywhere',\n",
              " 'to sit at the bar but anywhere else',\n",
              " 'sit at the bar but anywhere else is',\n",
              " 'at the bar but anywhere else is fine',\n",
              " 'we can<unk>t do those times <pad> <pad> <pad>',\n",
              " 'let<unk>s book that <pad> <pad> <pad> <pad> <pad>',\n",
              " 'that<unk>s it just book <pad> <pad> <pad> <pad>',\n",
              " 'watch another movie then <pad> <pad> <pad> <pad>',\n",
              " 'watch how to train your dragon <pad> <pad>',\n",
              " 'want to order a pi<unk><unk>a from bertuccis in',\n",
              " 'to order a pi<unk><unk>a from bertuccis in chelmsford',\n",
              " 'order a pi<unk><unk>a from bertuccis in chelmsford ma',\n",
              " 'want to order a pi<unk><unk>a from bertuccis in',\n",
              " 'to order a pi<unk><unk>a from bertuccis in chelmsford',\n",
              " 'order a pi<unk><unk>a from bertuccis in chelmsford ma',\n",
              " 'would like a sporkie pi<unk><unk>a <pad> <pad> <pad>',\n",
              " 'would like a sporkie pi<unk><unk>a <pad> <pad> <pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UXozikteB4g"
      },
      "source": [
        "int2token[0] = '<pad>'\r\n",
        "token2int['<pad>'] = 0"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdRX5nVHegCJ"
      },
      "source": [
        "vocab_size = len(int2token)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqFJ4eHlmjmX",
        "outputId": "7fad0ef2-8f35-491d-9f13-26e03b3c5206"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6775"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9oAOUoVemMR"
      },
      "source": [
        "def get_integer_seq(seq):\r\n",
        "  return[token2int[w] for w in seq.split()]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zINZzCgyjKQe"
      },
      "source": [
        "# convert text sequences to integer sequences\r\n",
        "x_tr_int = [get_integer_seq(i) for i in x_tr_padded]\r\n",
        "y_tr_int = [get_integer_seq(i) for i in y_tr_padded]\r\n",
        "\r\n",
        "x_val_int = [get_integer_seq(i) for i in x_val_padded]\r\n",
        "y_val_int = [get_integer_seq(i) for i in y_val_padded]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiYDQsoyjLYE",
        "outputId": "cba2c01c-2303-42c7-cc31-72a22675e4a8"
      },
      "source": [
        "x_tr_int[:10]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4596, 6176, 3669, 2229, 2735, 1380, 1644, 4094],\n",
              " [6176, 3669, 2229, 2735, 1380, 1644, 4094, 3308],\n",
              " [4549, 5861, 3560, 2229, 5514, 5944, 2877, 5127],\n",
              " [5861, 3560, 2229, 5514, 5944, 2877, 5127, 2453],\n",
              " [3560, 2229, 5514, 5944, 2877, 5127, 2453, 3819],\n",
              " [2229, 5514, 5944, 2877, 5127, 2453, 3819, 3882],\n",
              " [5514, 5944, 2877, 5127, 2453, 3819, 3882, 722],\n",
              " [6274, 4549, 3038, 2887, 1268, 0, 0, 0],\n",
              " [2351, 4861, 2735, 0, 0, 0, 0, 0],\n",
              " [6772, 5252, 5138, 311, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrcfOUl9jiYM",
        "outputId": "5898f6ca-bf3f-4acb-f9ec-0656ffd34d34"
      },
      "source": [
        "y_tr_int[:10]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6176, 3669, 2229, 2735, 1380, 1644, 4094, 3308],\n",
              " [3669, 2229, 2735, 1380, 1644, 4094, 3308, 182],\n",
              " [5861, 3560, 2229, 5514, 5944, 2877, 5127, 2453],\n",
              " [3560, 2229, 5514, 5944, 2877, 5127, 2453, 3819],\n",
              " [2229, 5514, 5944, 2877, 5127, 2453, 3819, 3882],\n",
              " [5514, 5944, 2877, 5127, 2453, 3819, 3882, 722],\n",
              " [5944, 2877, 5127, 2453, 3819, 3882, 722, 2697],\n",
              " [4549, 3038, 2887, 1268, 4516, 0, 0, 0],\n",
              " [4861, 2735, 3522, 0, 0, 0, 0, 0],\n",
              " [5252, 5138, 311, 2735, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YvlGMFRjliz"
      },
      "source": [
        "x_tr_int = np.array(x_tr_int)                     # converting data into array\r\n",
        "y_tr_int = np.array(y_tr_int)\r\n",
        "\r\n",
        "x_val_int = np.array(x_val_int)\r\n",
        "y_val_int = np.array(y_val_int)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG7jIdLEk8RW",
        "outputId": "1353f646-7c0a-4451-f397-9aff2621b484"
      },
      "source": [
        "x_tr_int.shape ,y_tr_int.shape ,x_val_int.shape , y_val_int.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 8), (50000, 8), (17993, 8), (17993, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vNidDI38NEd"
      },
      "source": [
        "# define model architecture\r\n",
        "\r\n",
        "## embedding layer: \r\n",
        "##    input dim = vocab_size, \r\n",
        "##    ouput dim = 200\r\n",
        "\r\n",
        "## LSTM layer:\r\n",
        "##    input dim = 200\r\n",
        "##    hidden units = 256\r\n",
        "##    layers = 2\r\n",
        "##    output dim = 256\r\n",
        "\r\n",
        "## Dropout Layer\r\n",
        "##    input dim = 256\r\n",
        "##    output dim = 256\r\n",
        "\r\n",
        "## fully connected layer\r\n",
        "##    input dim = 256\r\n",
        "##    ouput dim = vocab_size\r\n",
        "\r\n",
        "class WordLSTM(nn.Module):\r\n",
        "      \r\n",
        "  def __init__(self, n_hidden=256, n_layers=2, drop_prob=0.3, lr=0.001):\r\n",
        "    super().__init__()\r\n",
        "    self.drop_prob = drop_prob\r\n",
        "    self.n_layers = n_layers\r\n",
        "    self.n_hidden = n_hidden\r\n",
        "    self.lr = lr\r\n",
        "    \r\n",
        "    self.emb_layer = nn.Embedding(vocab_size, 200)\r\n",
        "\r\n",
        "    ## define the LSTM\r\n",
        "    # input data is of shape (batch size, sequence length, no. of features)...\r\n",
        "    # ...therefore we need batch_first=True\r\n",
        "    self.lstm = nn.LSTM(200, n_hidden, n_layers, batch_first=True)\r\n",
        "    \r\n",
        "    ## define a dropout layer\r\n",
        "    self.dropout = nn.Dropout(drop_prob)\r\n",
        "    \r\n",
        "    ## define the fully-connected layer\r\n",
        "    self.fc = nn.Linear(n_hidden, vocab_size)      \r\n",
        "  \r\n",
        "  def forward(self, x, hidden):\r\n",
        "    ''' Forward pass through the network. \r\n",
        "        These inputs are x, and the hidden/cell state is `hidden`. '''\r\n",
        "\r\n",
        "    ## pass input through embedding layer\r\n",
        "    embedded = self.emb_layer(x)     \r\n",
        "    \r\n",
        "    ## Get the outputs and the new hidden state from the lstm\r\n",
        "    lstm_output, hidden = self.lstm(embedded, hidden)\r\n",
        "    \r\n",
        "    ## pass through a dropout layer\r\n",
        "    out = self.dropout(lstm_output)\r\n",
        "    \r\n",
        "    ## reshape the tensor to the shape (batch-size*sequence length, hidden units)\r\n",
        "    out = out.reshape(-1, self.n_hidden)\r\n",
        "\r\n",
        "    ## put \"out\" through the fully-connected layer\r\n",
        "    out = self.fc(out)\r\n",
        "\r\n",
        "    # return the final output and the hidden state\r\n",
        "    return out, hidden\r\n",
        "    \r\n",
        "    \r\n",
        "  def init_hidden(self, batch_size):\r\n",
        "    ''' Initializes hidden state '''\r\n",
        "    # Create two new tensors with sizes n_layers x batch_size x n_hidden,\r\n",
        "    # initialized to zero, for hidden state and cell state of LSTM\r\n",
        "    weight = next(self.parameters()).data\r\n",
        "\r\n",
        "    if (torch.cuda.is_available()):\r\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\r\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\r\n",
        "    else:\r\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\r\n",
        "                weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\r\n",
        "    \r\n",
        "    return hidden"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4BM4tBm8OZC",
        "outputId": "82b6cf1e-b243-4946-e171-60effce8af36"
      },
      "source": [
        "net = WordLSTM()\r\n",
        "print(net)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(6775, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=6775, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTIn1df8sLu"
      },
      "source": [
        "# function to generate batches\r\n",
        "def get_batches(arr_x, arr_y, batch_size):\r\n",
        "  # iterate through the arrays\r\n",
        "  prv = 0\r\n",
        "  \r\n",
        "  for n in range(batch_size, arr_x.shape[0], batch_size):\r\n",
        "    # batch of input sequences\r\n",
        "    x = arr_x[prv:n,:]\r\n",
        "\r\n",
        "    # batch of target sequences\r\n",
        "    y = arr_y[prv:n,:]\r\n",
        "\r\n",
        "    prv = n\r\n",
        "    \r\n",
        "    yield x, y"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmeu7ewH8whY"
      },
      "source": [
        "def train(net, epochs=10, batch_size=32, lr=0.001, print_every=32):\r\n",
        "      \r\n",
        "  # set initial loss to infinite\r\n",
        "  best_valid_loss = float('inf')\r\n",
        "  \r\n",
        "  # optimizer\r\n",
        "  opt = torch.optim.Adam(net.parameters(), lr=lr)\r\n",
        "  \r\n",
        "  # loss function\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  \r\n",
        "  if(torch.cuda.is_available()):\r\n",
        "    # push model to GPU\r\n",
        "    net.cuda()\r\n",
        "  \r\n",
        "  counter = 0\r\n",
        "\r\n",
        "  net.train()\r\n",
        "\r\n",
        "  for e in range(epochs):\r\n",
        "            \r\n",
        "\r\n",
        "    # iterate over batches\r\n",
        "    for x, y in get_batches(x_tr_int, y_tr_int, batch_size):\r\n",
        "      counter+= 1\r\n",
        "      \r\n",
        "      # convert arrays to tensors\r\n",
        "      inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\r\n",
        "      \r\n",
        "      if(torch.cuda.is_available()):\r\n",
        "        # push tensors to GPU\r\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\r\n",
        "\r\n",
        "      # initialize hidden state\r\n",
        "      h = net.init_hidden(batch_size)\r\n",
        "\r\n",
        "      # set accumulated gradients to zero\r\n",
        "      net.zero_grad()\r\n",
        "      \r\n",
        "      # get the output from the model\r\n",
        "      output, h = net(inputs, h)\r\n",
        "      \r\n",
        "      # calculate the loss and perform backprop\r\n",
        "      loss = criterion(output, targets.view(-1))\r\n",
        "      loss.backward()\r\n",
        "      \r\n",
        "      opt.step()\r\n",
        "      \r\n",
        "      if counter % print_every == 0:\r\n",
        "        # Get validation loss\r\n",
        "        \r\n",
        "        val_losses = []\r\n",
        "\r\n",
        "        net.eval()\r\n",
        "        for x, y in get_batches(x_val_int, y_val_int, batch_size):\r\n",
        "            \r\n",
        "          x, y = torch.from_numpy(x), torch.from_numpy(y)\r\n",
        "          \r\n",
        "          val_h = net.init_hidden(batch_size)\r\n",
        "\r\n",
        "          inputs, targets = x, y\r\n",
        "          if(torch.cuda.is_available()):\r\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\r\n",
        "\r\n",
        "          output, val_h = net(inputs, val_h)\r\n",
        "\r\n",
        "          val_loss = criterion(output, targets.view(-1))\r\n",
        "          val_losses.append(val_loss.item())\r\n",
        "\r\n",
        "        #save the best model\r\n",
        "        if np.mean(val_losses) < best_valid_loss:\r\n",
        "          best_valid_loss = np.mean(val_losses)\r\n",
        "          torch.save(net.state_dict(), 'saved_weights.pt')\r\n",
        "\r\n",
        "        net.train()\r\n",
        "\r\n",
        "      \r\n",
        "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\r\n",
        "              \"Step: {}...\".format(counter),\r\n",
        "              \"Loss: {:.4f}...\".format(loss.item()),\r\n",
        "              \"ppl: {:.4f} \".format(np.exp(np.mean(val_losses))),\r\n",
        "              \"Val Loss: {:.4f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M9AyJTi84xj",
        "outputId": "bdf507a0-0de5-45f3-c1ba-1928a0b447c2"
      },
      "source": [
        "# specify batch size\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# train the model\r\n",
        "train(net, batch_size = batch_size, epochs=10)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10... Step: 32... Loss: 6.4530... ppl: 446.1121  Val Loss: 6.1006\n",
            "Epoch: 1/10... Step: 64... Loss: 5.1180... ppl: 311.0262  Val Loss: 5.7399\n",
            "Epoch: 1/10... Step: 96... Loss: 5.4498... ppl: 273.5889  Val Loss: 5.6116\n",
            "Epoch: 1/10... Step: 128... Loss: 5.5312... ppl: 219.5122  Val Loss: 5.3914\n",
            "Epoch: 1/10... Step: 160... Loss: 5.4962... ppl: 198.5211  Val Loss: 5.2909\n",
            "Epoch: 1/10... Step: 192... Loss: 6.1670... ppl: 179.3302  Val Loss: 5.1892\n",
            "Epoch: 1/10... Step: 224... Loss: 5.5782... ppl: 167.7657  Val Loss: 5.1226\n",
            "Epoch: 1/10... Step: 256... Loss: 5.4947... ppl: 157.3091  Val Loss: 5.0582\n",
            "Epoch: 1/10... Step: 288... Loss: 4.4379... ppl: 148.4424  Val Loss: 5.0002\n",
            "Epoch: 1/10... Step: 320... Loss: 4.8714... ppl: 139.5263  Val Loss: 4.9383\n",
            "Epoch: 1/10... Step: 352... Loss: 5.2926... ppl: 130.8630  Val Loss: 4.8742\n",
            "Epoch: 1/10... Step: 384... Loss: 4.2742... ppl: 124.6333  Val Loss: 4.8254\n",
            "Epoch: 1/10... Step: 416... Loss: 4.0556... ppl: 119.3471  Val Loss: 4.7820\n",
            "Epoch: 1/10... Step: 448... Loss: 4.7758... ppl: 115.9896  Val Loss: 4.7535\n",
            "Epoch: 1/10... Step: 480... Loss: 4.8101... ppl: 111.5274  Val Loss: 4.7143\n",
            "Epoch: 1/10... Step: 512... Loss: 4.6107... ppl: 107.6152  Val Loss: 4.6786\n",
            "Epoch: 1/10... Step: 544... Loss: 4.1796... ppl: 103.7107  Val Loss: 4.6416\n",
            "Epoch: 1/10... Step: 576... Loss: 4.3920... ppl: 103.1840  Val Loss: 4.6365\n",
            "Epoch: 1/10... Step: 608... Loss: 3.9625... ppl: 100.7320  Val Loss: 4.6125\n",
            "Epoch: 1/10... Step: 640... Loss: 4.9002... ppl: 96.9240  Val Loss: 4.5739\n",
            "Epoch: 1/10... Step: 672... Loss: 4.5546... ppl: 94.2893  Val Loss: 4.5464\n",
            "Epoch: 1/10... Step: 704... Loss: 5.1568... ppl: 91.8617  Val Loss: 4.5203\n",
            "Epoch: 1/10... Step: 736... Loss: 4.3778... ppl: 89.9535  Val Loss: 4.4993\n",
            "Epoch: 1/10... Step: 768... Loss: 3.9523... ppl: 88.1472  Val Loss: 4.4790\n",
            "Epoch: 2/10... Step: 800... Loss: 5.1705... ppl: 88.1798  Val Loss: 4.4794\n",
            "Epoch: 2/10... Step: 832... Loss: 4.3003... ppl: 88.9573  Val Loss: 4.4882\n",
            "Epoch: 2/10... Step: 864... Loss: 4.8579... ppl: 87.4931  Val Loss: 4.4716\n",
            "Epoch: 2/10... Step: 896... Loss: 4.0490... ppl: 86.3791  Val Loss: 4.4587\n",
            "Epoch: 2/10... Step: 928... Loss: 4.9166... ppl: 83.1442  Val Loss: 4.4206\n",
            "Epoch: 2/10... Step: 960... Loss: 3.4064... ppl: 83.0663  Val Loss: 4.4196\n",
            "Epoch: 2/10... Step: 992... Loss: 4.1139... ppl: 81.8682  Val Loss: 4.4051\n",
            "Epoch: 2/10... Step: 1024... Loss: 4.1530... ppl: 82.6280  Val Loss: 4.4143\n",
            "Epoch: 2/10... Step: 1056... Loss: 4.0915... ppl: 80.8568  Val Loss: 4.3927\n",
            "Epoch: 2/10... Step: 1088... Loss: 3.8818... ppl: 78.5648  Val Loss: 4.3639\n",
            "Epoch: 2/10... Step: 1120... Loss: 4.5998... ppl: 78.8192  Val Loss: 4.3672\n",
            "Epoch: 2/10... Step: 1152... Loss: 2.8423... ppl: 76.8091  Val Loss: 4.3413\n",
            "Epoch: 2/10... Step: 1184... Loss: 5.1069... ppl: 76.4923  Val Loss: 4.3372\n",
            "Epoch: 2/10... Step: 1216... Loss: 3.5616... ppl: 75.8054  Val Loss: 4.3282\n",
            "Epoch: 2/10... Step: 1248... Loss: 4.6778... ppl: 74.5873  Val Loss: 4.3120\n",
            "Epoch: 2/10... Step: 1280... Loss: 4.3371... ppl: 73.7189  Val Loss: 4.3003\n",
            "Epoch: 2/10... Step: 1312... Loss: 3.6062... ppl: 72.5921  Val Loss: 4.2849\n",
            "Epoch: 2/10... Step: 1344... Loss: 3.5621... ppl: 73.5065  Val Loss: 4.2974\n",
            "Epoch: 2/10... Step: 1376... Loss: 3.9062... ppl: 72.5717  Val Loss: 4.2846\n",
            "Epoch: 2/10... Step: 1408... Loss: 4.1499... ppl: 71.2336  Val Loss: 4.2660\n",
            "Epoch: 2/10... Step: 1440... Loss: 3.3183... ppl: 69.9529  Val Loss: 4.2478\n",
            "Epoch: 2/10... Step: 1472... Loss: 3.6492... ppl: 68.8356  Val Loss: 4.2317\n",
            "Epoch: 2/10... Step: 1504... Loss: 3.8810... ppl: 67.9850  Val Loss: 4.2193\n",
            "Epoch: 2/10... Step: 1536... Loss: 3.3505... ppl: 69.7256  Val Loss: 4.2446\n",
            "Epoch: 3/10... Step: 1568... Loss: 4.2723... ppl: 66.5820  Val Loss: 4.1984\n",
            "Epoch: 3/10... Step: 1600... Loss: 3.2537... ppl: 66.0893  Val Loss: 4.1910\n",
            "Epoch: 3/10... Step: 1632... Loss: 3.3249... ppl: 71.3341  Val Loss: 4.2674\n",
            "Epoch: 3/10... Step: 1664... Loss: 3.7764... ppl: 69.8936  Val Loss: 4.2470\n",
            "Epoch: 3/10... Step: 1696... Loss: 3.8765... ppl: 66.6243  Val Loss: 4.1991\n",
            "Epoch: 3/10... Step: 1728... Loss: 3.4516... ppl: 67.3573  Val Loss: 4.2100\n",
            "Epoch: 3/10... Step: 1760... Loss: 3.8931... ppl: 67.4189  Val Loss: 4.2109\n",
            "Epoch: 3/10... Step: 1792... Loss: 3.5975... ppl: 68.4479  Val Loss: 4.2261\n",
            "Epoch: 3/10... Step: 1824... Loss: 3.2434... ppl: 69.0328  Val Loss: 4.2346\n",
            "Epoch: 3/10... Step: 1856... Loss: 3.7961... ppl: 66.9088  Val Loss: 4.2033\n",
            "Epoch: 3/10... Step: 1888... Loss: 4.3344... ppl: 67.0289  Val Loss: 4.2051\n",
            "Epoch: 3/10... Step: 1920... Loss: 4.1599... ppl: 65.9649  Val Loss: 4.1891\n",
            "Epoch: 3/10... Step: 1952... Loss: 3.0802... ppl: 65.4689  Val Loss: 4.1816\n",
            "Epoch: 3/10... Step: 1984... Loss: 2.9799... ppl: 64.7753  Val Loss: 4.1709\n",
            "Epoch: 3/10... Step: 2016... Loss: 4.1785... ppl: 67.7940  Val Loss: 4.2165\n",
            "Epoch: 3/10... Step: 2048... Loss: 3.6283... ppl: 65.9761  Val Loss: 4.1893\n",
            "Epoch: 3/10... Step: 2080... Loss: 3.8343... ppl: 65.0589  Val Loss: 4.1753\n",
            "Epoch: 3/10... Step: 2112... Loss: 4.2937... ppl: 64.0447  Val Loss: 4.1596\n",
            "Epoch: 3/10... Step: 2144... Loss: 2.9085... ppl: 65.1874  Val Loss: 4.1773\n",
            "Epoch: 3/10... Step: 2176... Loss: 3.9493... ppl: 65.6130  Val Loss: 4.1838\n",
            "Epoch: 3/10... Step: 2208... Loss: 3.2486... ppl: 63.9396  Val Loss: 4.1579\n",
            "Epoch: 3/10... Step: 2240... Loss: 3.6045... ppl: 62.6888  Val Loss: 4.1382\n",
            "Epoch: 3/10... Step: 2272... Loss: 3.3168... ppl: 62.5943  Val Loss: 4.1367\n",
            "Epoch: 3/10... Step: 2304... Loss: 2.6054... ppl: 62.5302  Val Loss: 4.1356\n",
            "Epoch: 3/10... Step: 2336... Loss: 2.9149... ppl: 62.6126  Val Loss: 4.1370\n",
            "Epoch: 4/10... Step: 2368... Loss: 4.0110... ppl: 61.8293  Val Loss: 4.1244\n",
            "Epoch: 4/10... Step: 2400... Loss: 3.3469... ppl: 62.7818  Val Loss: 4.1397\n",
            "Epoch: 4/10... Step: 2432... Loss: 3.5552... ppl: 64.9320  Val Loss: 4.1733\n",
            "Epoch: 4/10... Step: 2464... Loss: 2.7966... ppl: 63.4147  Val Loss: 4.1497\n",
            "Epoch: 4/10... Step: 2496... Loss: 2.3083... ppl: 62.6578  Val Loss: 4.1377\n",
            "Epoch: 4/10... Step: 2528... Loss: 3.1561... ppl: 63.1243  Val Loss: 4.1451\n",
            "Epoch: 4/10... Step: 2560... Loss: 2.0535... ppl: 64.2833  Val Loss: 4.1633\n",
            "Epoch: 4/10... Step: 2592... Loss: 2.4062... ppl: 65.5308  Val Loss: 4.1825\n",
            "Epoch: 4/10... Step: 2624... Loss: 3.0961... ppl: 65.0503  Val Loss: 4.1752\n",
            "Epoch: 4/10... Step: 2656... Loss: 2.9088... ppl: 64.2890  Val Loss: 4.1634\n",
            "Epoch: 4/10... Step: 2688... Loss: 3.1502... ppl: 65.2285  Val Loss: 4.1779\n",
            "Epoch: 4/10... Step: 2720... Loss: 3.0007... ppl: 64.0749  Val Loss: 4.1601\n",
            "Epoch: 4/10... Step: 2752... Loss: 2.5848... ppl: 63.6769  Val Loss: 4.1538\n",
            "Epoch: 4/10... Step: 2784... Loss: 2.5216... ppl: 65.0216  Val Loss: 4.1747\n",
            "Epoch: 4/10... Step: 2816... Loss: 3.0759... ppl: 63.8565  Val Loss: 4.1566\n",
            "Epoch: 4/10... Step: 2848... Loss: 3.9927... ppl: 63.9291  Val Loss: 4.1578\n",
            "Epoch: 4/10... Step: 2880... Loss: 3.0668... ppl: 62.7640  Val Loss: 4.1394\n",
            "Epoch: 4/10... Step: 2912... Loss: 2.7966... ppl: 66.8926  Val Loss: 4.2031\n",
            "Epoch: 4/10... Step: 2944... Loss: 3.4309... ppl: 63.2856  Val Loss: 4.1477\n",
            "Epoch: 4/10... Step: 2976... Loss: 3.5388... ppl: 63.4580  Val Loss: 4.1504\n",
            "Epoch: 4/10... Step: 3008... Loss: 2.5467... ppl: 62.5777  Val Loss: 4.1364\n",
            "Epoch: 4/10... Step: 3040... Loss: 3.1728... ppl: 61.8507  Val Loss: 4.1247\n",
            "Epoch: 4/10... Step: 3072... Loss: 3.4441... ppl: 62.0765  Val Loss: 4.1284\n",
            "Epoch: 4/10... Step: 3104... Loss: 3.2442... ppl: 64.9025  Val Loss: 4.1729\n",
            "Epoch: 5/10... Step: 3136... Loss: 2.9630... ppl: 62.0311  Val Loss: 4.1276\n",
            "Epoch: 5/10... Step: 3168... Loss: 3.2868... ppl: 61.2523  Val Loss: 4.1150\n",
            "Epoch: 5/10... Step: 3200... Loss: 2.4410... ppl: 64.6590  Val Loss: 4.1691\n",
            "Epoch: 5/10... Step: 3232... Loss: 3.0189... ppl: 64.6845  Val Loss: 4.1695\n",
            "Epoch: 5/10... Step: 3264... Loss: 3.0394... ppl: 61.8164  Val Loss: 4.1242\n",
            "Epoch: 5/10... Step: 3296... Loss: 3.2034... ppl: 64.0410  Val Loss: 4.1595\n",
            "Epoch: 5/10... Step: 3328... Loss: 2.8118... ppl: 64.1765  Val Loss: 4.1616\n",
            "Epoch: 5/10... Step: 3360... Loss: 3.1335... ppl: 66.0749  Val Loss: 4.1908\n",
            "Epoch: 5/10... Step: 3392... Loss: 2.8210... ppl: 67.7657  Val Loss: 4.2161\n",
            "Epoch: 5/10... Step: 3424... Loss: 3.5933... ppl: 64.7959  Val Loss: 4.1712\n",
            "Epoch: 5/10... Step: 3456... Loss: 2.4611... ppl: 66.5036  Val Loss: 4.1973\n",
            "Epoch: 5/10... Step: 3488... Loss: 2.7835... ppl: 65.0208  Val Loss: 4.1747\n",
            "Epoch: 5/10... Step: 3520... Loss: 2.5265... ppl: 66.0374  Val Loss: 4.1902\n",
            "Epoch: 5/10... Step: 3552... Loss: 3.3186... ppl: 64.1793  Val Loss: 4.1617\n",
            "Epoch: 5/10... Step: 3584... Loss: 3.1306... ppl: 67.5285  Val Loss: 4.2126\n",
            "Epoch: 5/10... Step: 3616... Loss: 2.1566... ppl: 67.1226  Val Loss: 4.2065\n",
            "Epoch: 5/10... Step: 3648... Loss: 2.8258... ppl: 65.7297  Val Loss: 4.1856\n",
            "Epoch: 5/10... Step: 3680... Loss: 3.1778... ppl: 65.2039  Val Loss: 4.1775\n",
            "Epoch: 5/10... Step: 3712... Loss: 3.3337... ppl: 67.6188  Val Loss: 4.2139\n",
            "Epoch: 5/10... Step: 3744... Loss: 3.4231... ppl: 66.7628  Val Loss: 4.2011\n",
            "Epoch: 5/10... Step: 3776... Loss: 3.1171... ppl: 66.2725  Val Loss: 4.1938\n",
            "Epoch: 5/10... Step: 3808... Loss: 3.2468... ppl: 64.1797  Val Loss: 4.1617\n",
            "Epoch: 5/10... Step: 3840... Loss: 2.9556... ppl: 64.9133  Val Loss: 4.1731\n",
            "Epoch: 5/10... Step: 3872... Loss: 2.7922... ppl: 65.5336  Val Loss: 4.1826\n",
            "Epoch: 5/10... Step: 3904... Loss: 2.7759... ppl: 65.5217  Val Loss: 4.1824\n",
            "Epoch: 6/10... Step: 3936... Loss: 3.4628... ppl: 64.3513  Val Loss: 4.1644\n",
            "Epoch: 6/10... Step: 3968... Loss: 2.0114... ppl: 67.4964  Val Loss: 4.2121\n",
            "Epoch: 6/10... Step: 4000... Loss: 2.5781... ppl: 67.8281  Val Loss: 4.2170\n",
            "Epoch: 6/10... Step: 4032... Loss: 2.1492... ppl: 65.4450  Val Loss: 4.1812\n",
            "Epoch: 6/10... Step: 4064... Loss: 1.6885... ppl: 64.8351  Val Loss: 4.1718\n",
            "Epoch: 6/10... Step: 4096... Loss: 2.9573... ppl: 66.2672  Val Loss: 4.1937\n",
            "Epoch: 6/10... Step: 4128... Loss: 3.4779... ppl: 68.1854  Val Loss: 4.2222\n",
            "Epoch: 6/10... Step: 4160... Loss: 2.6732... ppl: 70.1200  Val Loss: 4.2502\n",
            "Epoch: 6/10... Step: 4192... Loss: 2.6742... ppl: 69.3598  Val Loss: 4.2393\n",
            "Epoch: 6/10... Step: 4224... Loss: 2.8753... ppl: 69.2482  Val Loss: 4.2377\n",
            "Epoch: 6/10... Step: 4256... Loss: 2.3287... ppl: 69.6641  Val Loss: 4.2437\n",
            "Epoch: 6/10... Step: 4288... Loss: 2.6421... ppl: 68.7076  Val Loss: 4.2299\n",
            "Epoch: 6/10... Step: 4320... Loss: 2.7172... ppl: 69.1812  Val Loss: 4.2367\n",
            "Epoch: 6/10... Step: 4352... Loss: 2.4565... ppl: 70.4376  Val Loss: 4.2547\n",
            "Epoch: 6/10... Step: 4384... Loss: 2.9282... ppl: 69.4420  Val Loss: 4.2405\n",
            "Epoch: 6/10... Step: 4416... Loss: 2.6039... ppl: 69.7461  Val Loss: 4.2449\n",
            "Epoch: 6/10... Step: 4448... Loss: 2.1233... ppl: 68.0658  Val Loss: 4.2205\n",
            "Epoch: 6/10... Step: 4480... Loss: 3.0805... ppl: 74.2411  Val Loss: 4.3073\n",
            "Epoch: 6/10... Step: 4512... Loss: 2.6424... ppl: 70.8291  Val Loss: 4.2603\n",
            "Epoch: 6/10... Step: 4544... Loss: 2.0313... ppl: 70.3260  Val Loss: 4.2531\n",
            "Epoch: 6/10... Step: 4576... Loss: 3.2066... ppl: 68.7696  Val Loss: 4.2308\n",
            "Epoch: 6/10... Step: 4608... Loss: 2.3970... ppl: 68.7855  Val Loss: 4.2310\n",
            "Epoch: 6/10... Step: 4640... Loss: 2.3819... ppl: 68.7689  Val Loss: 4.2308\n",
            "Epoch: 6/10... Step: 4672... Loss: 2.0606... ppl: 71.9835  Val Loss: 4.2764\n",
            "Epoch: 7/10... Step: 4704... Loss: 2.5649... ppl: 69.1297  Val Loss: 4.2360\n",
            "Epoch: 7/10... Step: 4736... Loss: 2.2055... ppl: 68.8219  Val Loss: 4.2315\n",
            "Epoch: 7/10... Step: 4768... Loss: 1.8265... ppl: 70.9340  Val Loss: 4.2617\n",
            "Epoch: 7/10... Step: 4800... Loss: 2.7664... ppl: 69.5786  Val Loss: 4.2425\n",
            "Epoch: 7/10... Step: 4832... Loss: 2.5767... ppl: 68.0390  Val Loss: 4.2201\n",
            "Epoch: 7/10... Step: 4864... Loss: 2.4874... ppl: 70.0207  Val Loss: 4.2488\n",
            "Epoch: 7/10... Step: 4896... Loss: 2.0400... ppl: 70.4515  Val Loss: 4.2549\n",
            "Epoch: 7/10... Step: 4928... Loss: 1.9620... ppl: 74.4992  Val Loss: 4.3108\n",
            "Epoch: 7/10... Step: 4960... Loss: 1.7777... ppl: 74.9187  Val Loss: 4.3164\n",
            "Epoch: 7/10... Step: 4992... Loss: 1.9564... ppl: 72.5961  Val Loss: 4.2849\n",
            "Epoch: 7/10... Step: 5024... Loss: 2.1499... ppl: 75.9199  Val Loss: 4.3297\n",
            "Epoch: 7/10... Step: 5056... Loss: 1.9909... ppl: 72.4015  Val Loss: 4.2822\n",
            "Epoch: 7/10... Step: 5088... Loss: 2.4849... ppl: 74.7332  Val Loss: 4.3139\n",
            "Epoch: 7/10... Step: 5120... Loss: 2.2981... ppl: 72.9066  Val Loss: 4.2892\n",
            "Epoch: 7/10... Step: 5152... Loss: 2.0726... ppl: 76.1030  Val Loss: 4.3321\n",
            "Epoch: 7/10... Step: 5184... Loss: 2.3895... ppl: 75.7690  Val Loss: 4.3277\n",
            "Epoch: 7/10... Step: 5216... Loss: 3.2275... ppl: 73.8455  Val Loss: 4.3020\n",
            "Epoch: 7/10... Step: 5248... Loss: 2.4409... ppl: 75.1452  Val Loss: 4.3194\n",
            "Epoch: 7/10... Step: 5280... Loss: 2.6631... ppl: 77.7615  Val Loss: 4.3536\n",
            "Epoch: 7/10... Step: 5312... Loss: 2.6877... ppl: 75.9204  Val Loss: 4.3297\n",
            "Epoch: 7/10... Step: 5344... Loss: 2.3737... ppl: 75.8591  Val Loss: 4.3289\n",
            "Epoch: 7/10... Step: 5376... Loss: 2.3481... ppl: 72.9322  Val Loss: 4.2895\n",
            "Epoch: 7/10... Step: 5408... Loss: 2.2919... ppl: 74.7704  Val Loss: 4.3144\n",
            "Epoch: 7/10... Step: 5440... Loss: 2.0840... ppl: 75.2158  Val Loss: 4.3204\n",
            "Epoch: 8/10... Step: 5472... Loss: 1.9337... ppl: 74.6442  Val Loss: 4.3127\n",
            "Epoch: 8/10... Step: 5504... Loss: 2.5684... ppl: 72.7653  Val Loss: 4.2872\n",
            "Epoch: 8/10... Step: 5536... Loss: 1.7437... ppl: 77.3838  Val Loss: 4.3488\n",
            "Epoch: 8/10... Step: 5568... Loss: 1.8670... ppl: 75.8641  Val Loss: 4.3289\n",
            "Epoch: 8/10... Step: 5600... Loss: 2.4922... ppl: 73.2233  Val Loss: 4.2935\n",
            "Epoch: 8/10... Step: 5632... Loss: 1.9361... ppl: 73.8871  Val Loss: 4.3025\n",
            "Epoch: 8/10... Step: 5664... Loss: 2.5015... ppl: 75.3635  Val Loss: 4.3223\n",
            "Epoch: 8/10... Step: 5696... Loss: 2.3411... ppl: 77.3045  Val Loss: 4.3478\n",
            "Epoch: 8/10... Step: 5728... Loss: 1.3111... ppl: 81.1786  Val Loss: 4.3967\n",
            "Epoch: 8/10... Step: 5760... Loss: 2.0576... ppl: 78.8300  Val Loss: 4.3673\n",
            "Epoch: 8/10... Step: 5792... Loss: 2.2760... ppl: 78.1316  Val Loss: 4.3584\n",
            "Epoch: 8/10... Step: 5824... Loss: 1.8711... ppl: 79.4847  Val Loss: 4.3756\n",
            "Epoch: 8/10... Step: 5856... Loss: 1.9430... ppl: 78.2104  Val Loss: 4.3594\n",
            "Epoch: 8/10... Step: 5888... Loss: 1.7174... ppl: 78.9177  Val Loss: 4.3684\n",
            "Epoch: 8/10... Step: 5920... Loss: 2.2706... ppl: 81.5225  Val Loss: 4.4009\n",
            "Epoch: 8/10... Step: 5952... Loss: 1.9445... ppl: 79.3276  Val Loss: 4.3736\n",
            "Epoch: 8/10... Step: 5984... Loss: 2.1035... ppl: 81.0676  Val Loss: 4.3953\n",
            "Epoch: 8/10... Step: 6016... Loss: 2.2144... ppl: 79.0052  Val Loss: 4.3695\n",
            "Epoch: 8/10... Step: 6048... Loss: 2.2528... ppl: 85.4215  Val Loss: 4.4476\n",
            "Epoch: 8/10... Step: 6080... Loss: 2.3815... ppl: 82.5888  Val Loss: 4.4139\n",
            "Epoch: 8/10... Step: 6112... Loss: 2.3424... ppl: 82.8425  Val Loss: 4.4169\n",
            "Epoch: 8/10... Step: 6144... Loss: 1.7769... ppl: 79.2359  Val Loss: 4.3724\n",
            "Epoch: 8/10... Step: 6176... Loss: 2.1817... ppl: 80.6066  Val Loss: 4.3896\n",
            "Epoch: 8/10... Step: 6208... Loss: 2.0849... ppl: 80.4270  Val Loss: 4.3873\n",
            "Epoch: 8/10... Step: 6240... Loss: 2.1346... ppl: 83.6668  Val Loss: 4.4268\n",
            "Epoch: 9/10... Step: 6272... Loss: 1.9612... ppl: 79.6446  Val Loss: 4.3776\n",
            "Epoch: 9/10... Step: 6304... Loss: 1.6762... ppl: 81.5076  Val Loss: 4.4007\n",
            "Epoch: 9/10... Step: 6336... Loss: 2.1893... ppl: 83.1656  Val Loss: 4.4208\n",
            "Epoch: 9/10... Step: 6368... Loss: 1.8153... ppl: 79.5003  Val Loss: 4.3758\n",
            "Epoch: 9/10... Step: 6400... Loss: 2.2250... ppl: 79.0077  Val Loss: 4.3695\n",
            "Epoch: 9/10... Step: 6432... Loss: 2.2209... ppl: 81.2212  Val Loss: 4.3972\n",
            "Epoch: 9/10... Step: 6464... Loss: 2.0674... ppl: 80.7916  Val Loss: 4.3919\n",
            "Epoch: 9/10... Step: 6496... Loss: 1.6910... ppl: 86.5968  Val Loss: 4.4613\n",
            "Epoch: 9/10... Step: 6528... Loss: 1.3849... ppl: 86.2832  Val Loss: 4.4576\n",
            "Epoch: 9/10... Step: 6560... Loss: 2.1020... ppl: 84.6043  Val Loss: 4.4380\n",
            "Epoch: 9/10... Step: 6592... Loss: 2.2469... ppl: 88.4068  Val Loss: 4.4819\n",
            "Epoch: 9/10... Step: 6624... Loss: 1.9151... ppl: 83.9683  Val Loss: 4.4304\n",
            "Epoch: 9/10... Step: 6656... Loss: 2.1085... ppl: 86.4985  Val Loss: 4.4601\n",
            "Epoch: 9/10... Step: 6688... Loss: 1.9798... ppl: 85.6551  Val Loss: 4.4503\n",
            "Epoch: 9/10... Step: 6720... Loss: 1.8213... ppl: 87.8828  Val Loss: 4.4760\n",
            "Epoch: 9/10... Step: 6752... Loss: 1.7582... ppl: 86.8838  Val Loss: 4.4646\n",
            "Epoch: 9/10... Step: 6784... Loss: 2.1141... ppl: 86.6018  Val Loss: 4.4613\n",
            "Epoch: 9/10... Step: 6816... Loss: 1.7677... ppl: 88.6200  Val Loss: 4.4844\n",
            "Epoch: 9/10... Step: 6848... Loss: 2.3718... ppl: 90.6413  Val Loss: 4.5069\n",
            "Epoch: 9/10... Step: 6880... Loss: 1.7097... ppl: 87.4419  Val Loss: 4.4710\n",
            "Epoch: 9/10... Step: 6912... Loss: 1.9610... ppl: 88.6167  Val Loss: 4.4843\n",
            "Epoch: 9/10... Step: 6944... Loss: 2.0412... ppl: 85.4677  Val Loss: 4.4481\n",
            "Epoch: 9/10... Step: 6976... Loss: 1.3136... ppl: 87.4598  Val Loss: 4.4712\n",
            "Epoch: 9/10... Step: 7008... Loss: 2.0079... ppl: 88.9058  Val Loss: 4.4876\n",
            "Epoch: 10/10... Step: 7040... Loss: 2.2263... ppl: 87.8452  Val Loss: 4.4756\n",
            "Epoch: 10/10... Step: 7072... Loss: 2.1289... ppl: 85.1711  Val Loss: 4.4447\n",
            "Epoch: 10/10... Step: 7104... Loss: 1.8069... ppl: 90.4509  Val Loss: 4.5048\n",
            "Epoch: 10/10... Step: 7136... Loss: 2.1295... ppl: 87.1018  Val Loss: 4.4671\n",
            "Epoch: 10/10... Step: 7168... Loss: 2.1048... ppl: 84.9834  Val Loss: 4.4425\n",
            "Epoch: 10/10... Step: 7200... Loss: 1.8555... ppl: 86.1699  Val Loss: 4.4563\n",
            "Epoch: 10/10... Step: 7232... Loss: 1.7042... ppl: 86.9784  Val Loss: 4.4657\n",
            "Epoch: 10/10... Step: 7264... Loss: 1.7329... ppl: 90.4877  Val Loss: 4.5052\n",
            "Epoch: 10/10... Step: 7296... Loss: 1.8078... ppl: 96.6015  Val Loss: 4.5706\n",
            "Epoch: 10/10... Step: 7328... Loss: 1.9931... ppl: 91.3890  Val Loss: 4.5151\n",
            "Epoch: 10/10... Step: 7360... Loss: 2.2472... ppl: 92.2315  Val Loss: 4.5243\n",
            "Epoch: 10/10... Step: 7392... Loss: 1.9154... ppl: 92.5700  Val Loss: 4.5280\n",
            "Epoch: 10/10... Step: 7424... Loss: 2.0000... ppl: 91.3364  Val Loss: 4.5145\n",
            "Epoch: 10/10... Step: 7456... Loss: 1.5124... ppl: 91.6338  Val Loss: 4.5178\n",
            "Epoch: 10/10... Step: 7488... Loss: 1.7580... ppl: 93.5932  Val Loss: 4.5390\n",
            "Epoch: 10/10... Step: 7520... Loss: 1.4399... ppl: 93.3687  Val Loss: 4.5366\n",
            "Epoch: 10/10... Step: 7552... Loss: 1.6779... ppl: 94.8368  Val Loss: 4.5522\n",
            "Epoch: 10/10... Step: 7584... Loss: 1.8378... ppl: 92.4476  Val Loss: 4.5266\n",
            "Epoch: 10/10... Step: 7616... Loss: 2.1566... ppl: 100.4172  Val Loss: 4.6093\n",
            "Epoch: 10/10... Step: 7648... Loss: 1.7135... ppl: 96.4670  Val Loss: 4.5692\n",
            "Epoch: 10/10... Step: 7680... Loss: 2.1516... ppl: 97.5981  Val Loss: 4.5809\n",
            "Epoch: 10/10... Step: 7712... Loss: 1.6470... ppl: 92.2465  Val Loss: 4.5245\n",
            "Epoch: 10/10... Step: 7744... Loss: 1.6280... ppl: 95.1483  Val Loss: 4.5554\n",
            "Epoch: 10/10... Step: 7776... Loss: 1.6607... ppl: 95.5986  Val Loss: 4.5602\n",
            "Epoch: 10/10... Step: 7808... Loss: 2.2009... ppl: 97.2097  Val Loss: 4.5769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzNfa6yH88Ra",
        "outputId": "134d4131-5d49-4f60-8f1e-7396265036f8"
      },
      "source": [
        "#load weights of best model\r\n",
        "path = 'saved_weights.pt'\r\n",
        "net.load_state_dict(torch.load(path))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-YqXJcS9NoR"
      },
      "source": [
        "# function to generate one token\r\n",
        "def predict(net, tkn, h=None):\r\n",
        "         \r\n",
        "  # tensor inputs\r\n",
        "  x = np.array([[token2int[tkn]]])\r\n",
        "  inputs = torch.from_numpy(x)\r\n",
        "  \r\n",
        "  if(torch.cuda.is_available()):\r\n",
        "      inputs = inputs.cuda()\r\n",
        "\r\n",
        "  # get the output of the model\r\n",
        "  out, h = net(inputs, h)\r\n",
        "\r\n",
        "  # get the token probabilities\r\n",
        "  p = F.softmax(out, dim=1).data\r\n",
        "\r\n",
        "  if(torch.cuda.is_available()):\r\n",
        "      p = p.cpu()\r\n",
        "\r\n",
        "  p = p.numpy()\r\n",
        "  sampled_token_index = np.argmax(p, axis = 1)[0]\r\n",
        "  \r\n",
        "  # return the encoded value of the predicted char and the hidden state\r\n",
        "  return int2token[sampled_token_index], h"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q20WDo6x9PgN"
      },
      "source": [
        "# function to fetch generated sequence\r\n",
        "def sample(net, size = 2, seed_text='it is'):\r\n",
        "        \r\n",
        "    if(torch.cuda.is_available()):\r\n",
        "        net.cuda()\r\n",
        "    \r\n",
        "    net.eval()\r\n",
        "\r\n",
        "    # batch size is 1\r\n",
        "    h = net.init_hidden(1)\r\n",
        "\r\n",
        "    toks = seed_text.split()\r\n",
        "\r\n",
        "    # predict next token\r\n",
        "    for t in toks:\r\n",
        "      token, h = predict(net, t, h)\r\n",
        "    \r\n",
        "    toks.append(token)\r\n",
        "\r\n",
        "    # predict subsequent tokens\r\n",
        "    for i in range(size-1):\r\n",
        "        token, h = predict(net, toks[-1], h)\r\n",
        "        toks.append(token)\r\n",
        "\r\n",
        "    return ' '.join(toks)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uzsZ1De9WQN",
        "outputId": "3f337db0-97bd-48b0-8ea0-79ca4030ebac"
      },
      "source": [
        "# seed texts\r\n",
        "seeds = [\"i want to\",\r\n",
        "         \"how about a cup\",\r\n",
        "         \"i don't want\",\r\n",
        "         \"can you send\",\r\n",
        "         \"my car\"]\r\n",
        "\r\n",
        "# number of tokens to generate\r\n",
        "num_toks = 6\r\n",
        "\r\n",
        "# text generation\r\n",
        "for s in seeds:\r\n",
        "  # get generated text from the model\r\n",
        "  text_gen = sample(net, num_toks, seed_text=s)\r\n",
        "  # print the result\r\n",
        "  print(\"seed text:\", s, \">> output:\",text_gen)\r\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed text: i want to >> output: i want to order a pi<unk><unk>a from pi<unk><unk>a hut\n",
            "\n",
            "\n",
            "seed text: how about a cup >> output: how about a cup of pi<unk><unk>a hut and i want\n",
            "\n",
            "\n",
            "seed text: i don't want >> output: i don't want to go to the movies tonight\n",
            "\n",
            "\n",
            "seed text: can you send >> output: can you send a pi<unk><unk>a for me from the\n",
            "\n",
            "\n",
            "seed text: my car >> output: my car is making a bit noise and\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}